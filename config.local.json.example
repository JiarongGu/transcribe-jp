{
  // This is an example config.local.json file for local overrides
  // Copy this to config.local.json and customize (it's gitignored)
  // Only include settings you want to override from config.json

  "whisper": {
    "device": "cuda"
  },

  "llm": {
    // Choose provider: "ollama" (free, local, auto-managed), "anthropic" (paid, high quality), or "openai" (paid)
    "provider": "anthropic",

    "ollama": {
      "model": "llama3.2:3b"
      // "base_url": "http://localhost:11434"  // Optional: Use external Ollama server
    },

    "anthropic": {
      "api_key": "sk-ant-api03-your-actual-key-here",
      "model": "claude-3-5-haiku-20241022"
    },

    "openai": {
      "api_key": "sk-proj-your-actual-key-here",
      "model": "gpt-4o-mini"
    }
  },

  "segment_splitting": {
    "enable_llm": true
    // "llm_provider": "ollama"  // Uncomment to override global provider for this stage
  },

  "text_polishing": {
    "enable": true
    // "llm_provider": "anthropic"  // Uncomment to override global provider for this stage
  },

  "timing_realignment": {
    "enable": true
  }

  // ============================================================================
  // EXAMPLE CONFIGURATIONS (remove this section in your actual config.local.json)
  // ============================================================================

  // Example 1: FREE Ollama only
  // {
  //   "llm": {
  //     "provider": "ollama",
  //     "ollama": {
  //       "model": "llama3.2:3b"
  //     }
  //   }
  // }

  // Example 2: Anthropic only
  // {
  //   "llm": {
  //     "provider": "anthropic",
  //     "anthropic": {
  //       "api_key": "sk-ant-..."
  //     }
  //   }
  // }

  // Example 3: Hybrid - FREE Ollama for splitting, paid Claude for polishing
  // {
  //   "llm": {
  //     "provider": "ollama",
  //     "ollama": {
  //       "model": "llama3.2:3b"
  //     },
  //     "anthropic": {
  //       "api_key": "sk-ant-..."
  //     }
  //   },
  //   "segment_splitting": {
  //     "enable_llm": true
  //     // Uses global "ollama" provider (FREE)
  //   },
  //   "text_polishing": {
  //     "enable": true,
  //     "llm_provider": "anthropic"  // Override to use Anthropic for this stage
  //   }
  // }

  // For detailed LLM configuration guide, see: docs/features/LLM_PROVIDERS.md
}
